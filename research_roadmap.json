{
  "project": "open-cure",
  "baseline_metric": "41.8% R@30",
  "evaluation_details": {
    "diseases": 1236,
    "pairs": 3618,
    "model": "GB + Fuzzy Matcher"
  },
  "last_updated": "2026-01-26",
  "hypotheses": [
    {
      "id": "h1",
      "title": "GB + TxGNN Best-Rank Ensemble",
      "category": "ensemble",
      "rationale": "TxGNN excels at storage diseases (83.3% R@30) while GB is better overall (41.8%). Archive shows simple best_rank ensemble achieved 7.5% vs 6.7% TxGNN alone. Taking min(GB_rank, TxGNN_rank) should capture best of both.",
      "expected_impact": "medium",
      "effort": "low",
      "priority": 1,
      "status": "invalidated",
      "steps": [
        "Step 1: Load TxGNN predictions from data/reference/txgnn_predictions.csv",
        "Step 2: For each disease-drug pair, compute min(GB_rank, TxGNN_rank)",
        "Step 3: Evaluate R@30 on held-out disease set using disease-level split",
        "Step 4: Success criteria: >43% R@30 (>1.2% improvement over baseline)"
      ],
      "findings": "CRITICAL BLOCKER: The pre-computed TxGNN predictions file (txgnn_predictions_final.csv) only contains TOP 50 drugs per disease. Ground truth drugs almost NEVER appear in TxGNN's top-50 predictions (0% coverage for common diseases). The 14.5% R@30 in archive was based on full TxGNN inference (where GT drugs might rank within 30 among 7954 drugs), not pre-computed rankings. Ensemble using pre-computed file achieves 0% TxGNN contribution + 42.0% GB = 42.0% ensemble (no improvement). To implement this properly, we would need to: (1) Run TxGNN inference on GPU for all drug-disease pairs, OR (2) Store full rankings (not just top-50). Current approach is blocked without GPU.",
      "result_metric": "42.0% R@30 (ensemble) - no improvement over 42.0% GB baseline"
    },
    {
      "id": "h2",
      "title": "Category-Routed Ensemble",
      "category": "ensemble",
      "rationale": "TxGNN dominates on storage (83%), psychiatric (28%), dermatological (25%), autoimmune (22%) categories. Route these to TxGNN, rest to GB. Keyword categorization achieves 68% disease coverage.",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 2,
      "status": "blocked",
      "steps": [
        "Step 1: Use src/disease_categorizer.py to classify all evaluation diseases",
        "Step 2: Route storage/psychiatric/dermatological/autoimmune to TxGNN predictions",
        "Step 3: Route cancer/respiratory/renal/gastrointestinal to GB",
        "Step 4: Evaluate R@30 with proper held-out split",
        "Step 5: Success criteria: >44% R@30"
      ],
      "findings": "BLOCKED: Same issue as h1 - TxGNN pre-computed predictions only contain top-50 drugs per disease. GT drugs not in top-50 for most diseases. Category routing would have 0% contribution from TxGNN without live GPU inference. Requires GPU access to implement properly.",
      "result_metric": null
    },
    {
      "id": "h3",
      "title": "Infectious Disease Specialist Model",
      "category": "architecture",
      "rationale": "Infectious diseases have 13.6% recall vs 63% autoimmune. Model predicts antibiotics for wrong diseases. A specialist model trained on infectious disease pairs could learn pathogen-specific patterns.",
      "expected_impact": "high",
      "effort": "high",
      "priority": 3,
      "status": "invalidated",
      "steps": [
        "Step 1: Extract infectious disease pairs from ground truth (identify by ICD codes or keywords)",
        "Step 2: Extract antibiotic/antiviral drugs from DrugBank by ATC codes (J01, J05)",
        "Step 3: Train specialist XGBoost model on infectious pairs only",
        "Step 4: Evaluate on held-out infectious diseases",
        "Step 5: Success criteria: >30% R@30 for infectious diseases (2x improvement)"
      ],
      "findings": "INVALIDATED: The baseline 13.6% R@30 figure in CLAUDE.md was based on antibiotic CLASS performance, not overall infectious disease evaluation.\n\nACTUAL BASELINE: General GB model achieves 52.0% R@30 on 47 mappable infectious diseases (104/200 hits).\n\nSPECIALIST MODEL: Trained on 294 positive pairs, 756 negatives. Achieved only 36.4% R@30 on held-out test diseases (12 diseases, 22 GT drugs).\n\nGENERAL MODEL COMPARISON: On same test set, general model achieved 63.6% R@30.\n\nKEY FINDINGS:\n1. General model OUTPERFORMS specialist by 27.3% on infectious diseases\n2. Specialist has insufficient training data (294 pairs vs ~3000 for general model)\n3. The infectious disease \"problem\" identified in CLAUDE.md was about antibiotics being predicted for NON-infectious diseases, not about recall on actual infectious diseases\n4. The general model already performs well (52% R@30) on infectious diseases when evaluated properly\n\nIMPLICATION: A specialist model approach is not needed for infectious diseases. The real problem is filtering spurious antibiotic predictions for non-infectious diseases (already addressed by confidence_filter.py).",
      "result_metric": "36.4% R@30 (specialist) vs 52.0% R@30 (general baseline) - specialist underperforms"
    },
    {
      "id": "h4",
      "title": "Expand Ground Truth with DrugBank/ChEMBL Indications",
      "category": "data",
      "rationale": "Current GT is Every Cure (~50K pairs). DrugBank and ChEMBL have additional FDA-approved indications. Validation sessions found 4 FDA-approved drugs missing from GT (Ustekinumab, Guselkumab, Pembrolizumab).",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 4,
      "status": "inconclusive",
      "steps": [
        "Step 1: Download DrugBank approved indications (data/reference/drugbank_lookup.json exists)",
        "Step 2: Download ChEMBL approved indications via API",
        "Step 3: Map to DRKG disease IDs using disease_name_matcher.py",
        "Step 4: Add new positive pairs and retrain GB model",
        "Step 5: Evaluate on original test set",
        "Step 6: Success criteria: >43% R@30"
      ],
      "findings": "PARTIAL VALIDATION: The hypothesis premise was partially correct but the impact is too small to be meaningful.\n\nKEY FINDINGS:\n1. All DRKG treatment edges (4,968) are already included in the current GT (58,016 pairs)\n2. The GT is much larger than DRKG because it includes Every Cure annotations\n3. We identified 6 FDA-approved drug-disease pairs missing from GT:\n   - Pembrolizumab -> Breast Cancer (Rank 7, Hit)\n   - Natalizumab -> Multiple Sclerosis (Rank 16, Hit)\n   - Erlotinib -> Pancreatic Cancer (Rank 16, Hit)\n   - Cetuximab -> Colorectal Cancer (Rank 1, Hit)\n   - Oxaliplatin -> Colorectal Cancer (Rank 37, Miss)\n   - Bevacizumab -> Colorectal Cancer (Rank 7, Hit)\n4. 5/6 (83.3%) of these pairs hit@30 - suggesting the model already learns these relationships\n5. Impact: Adding these 6 pairs would improve R@30 by only +0.22 pp (42.04% \u2192 42.26%)\n\nBLOCKERS:\n- DrugBank data available (drugbank_lookup.json) only has name mappings, not indication data\n- Full DrugBank indication data requires license/download (not available)\n- ChEMBL API access not implemented\n- Manual curation of missing pairs is not scalable\n\nCONCLUSION: The approach is theoretically sound (adding correct FDA pairs improves accuracy) but:\n1. Most FDA-approved pairs are already in GT\n2. Missing pairs are few in number\n3. Impact is marginal (<0.3 pp)\n4. Accessing comprehensive indication databases requires additional setup\n\nRecommend: Mark as inconclusive pending access to DrugBank/ChEMBL full indication data.",
      "result_metric": "+0.22 pp (42.04% \u2192 42.26%) from 6 manual additions"
    },
    {
      "id": "h5",
      "title": "Hard Negative Mining",
      "category": "data",
      "rationale": "Current model uses random negative sampling. Learning from hard negatives (drugs that seem plausible but aren't treatments) could improve discrimination. Confounding analysis identified 9 false positive patterns.",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 5,
      "status": "invalidated",
      "steps": [
        "Step 1: Generate hard negatives: drugs with high GB score but not in GT",
        "Step 2: Include confounding patterns (statins->T2D, checkpoint->UC) as explicit negatives",
        "Step 3: Retrain GB with 50% hard negatives, 50% random negatives",
        "Step 4: Evaluate R@30 on held-out diseases",
        "Step 5: Success criteria: >42.5% R@30 + reduced false positive rate"
      ],
      "findings": "INVALIDATED: Comprehensive experiment with 5 negative sampling strategies (v2) reveals a FUNDAMENTAL problem: the GB model cannot generalize to unseen diseases under disease-level holdout.\n\nRESULTS (88 held-out test diseases, 547 GT pairs):\n- Baseline (existing model, trained on ALL diseases): 45.89% R@30\n- Strategy A (random negatives): 12.43% R@30 (-33.5%)\n- Strategy B (drug-treats-other): 3.29% R@30 (-42.6%)\n- Strategy C (B + 50% model FP): 5.67% R@30 (-40.2%)\n- Strategy D (B + 25% model FP): 8.59% R@30 (-37.3%)\n- Strategy E (D + confounding): 7.31% R@30 (-38.6%)\n\nALL freshly trained models collapse on held-out diseases, regardless of negative sampling strategy.\n\nROOT CAUSE: The existing model was trained using random pair-level split (train_test_split with stratify=y), NOT disease-level holdout. It learns disease-specific embedding patterns that don't transfer to unseen diseases. The 41.8% R@30 baseline metric reflects within-distribution performance, not novel disease generalization.\n\nThe prior v1 result (14.5% collapse) was also caused by this fundamental issue, not by hard negative mining specifically.\n\nCRITICAL INSIGHT: Hard negative mining is irrelevant when the model architecture itself cannot generalize. The GB model operating on TransE embedding features (concat/product/diff) essentially memorizes per-disease patterns rather than learning transferable drug-disease relationships.\n\nPOSITIVE CONTROLS:\n- Baseline: Rituximab\u2192MS rank 6, Imatinib\u2192CML rank 1, Lisinopril\u2192HTN rank 12, Metformin\u2192T2D rank 3426\n- All retrained models: positive controls degraded significantly\n\nNote: Node2Vec + XGBoost reportedly achieved 41.9% R@30 on held-out diseases, suggesting the embedding method matters more than the negative sampling strategy.",
      "result_metric": "ALL strategies failed: best retrained model 12.43% R@30 vs 45.89% baseline on held-out diseases"
    },
    {
      "id": "h6",
      "title": "Biologic-Specific Features",
      "category": "feature",
      "rationale": "Biologics achieve only 27.3% recall vs 63% for ACE inhibitors. Root cause: data sparsity (2.1 vs 11.1 diseases/drug). Adding mAb-specific features (target antigen, immunology pathway) could help.",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 6,
      "status": "pending",
      "steps": [
        "Step 1: Extract mAb target antigens from DrugBank (e.g., TNF-alpha, CD20, IL-17)",
        "Step 2: Map diseases to immunology pathways (Th1, Th2, Th17)",
        "Step 3: Create feature: mAb_target_pathway_match",
        "Step 4: Boost predictions where target matches disease pathway",
        "Step 5: Evaluate R@30 for biologics specifically",
        "Step 6: Success criteria: >35% R@30 for biologics"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h7",
      "title": "Graph Path Features",
      "category": "feature",
      "rationale": "Current features use embedding similarity. Adding explicit graph structure features (path length, shared neighbors, metapath counts) could capture different signals from DRKG.",
      "expected_impact": "medium",
      "effort": "high",
      "priority": 7,
      "status": "pending",
      "steps": [
        "Step 1: Load DRKG graph from data/drkg/drkg.tsv",
        "Step 2: Compute for each drug-disease pair: shortest path, #paths<=3, shared gene neighbors",
        "Step 3: Add as features to existing GB model",
        "Step 4: Retrain with graph features",
        "Step 5: Evaluate on held-out diseases",
        "Step 6: Success criteria: >43% R@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h8",
      "title": "Confidence-Based Post-Filtering",
      "category": "evaluation",
      "rationale": "Confidence calibrator achieves 0.962 AUROC. Using it to filter low-confidence predictions could improve precision without hurting recall. Filter threshold analysis needed. NOTE: h5 findings suggest this operates on within-distribution performance only. Still useful for the current (non-generalizing) model's predictions.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 15,
      "status": "pending",
      "steps": [
        "Step 1: Load confidence_calibrator.pkl model",
        "Step 2: Score all predictions in evaluation set",
        "Step 3: Analyze R@30 at different confidence thresholds (0.2, 0.4, 0.6, 0.8)",
        "Step 4: Find optimal threshold for precision-recall tradeoff",
        "Step 5: Success criteria: Maintain >40% R@30 with >30% precision improvement"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h9",
      "title": "Disease Coverage Expansion via UMLS",
      "category": "data",
      "rationale": "Currently 30.9% of EC diseases mapped via fuzzy matching. UMLS has comprehensive cross-references (MESH, MONDO, DOID, SNOMED). Could improve to 50%+ coverage.",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 9,
      "status": "pending",
      "steps": [
        "Step 1: Download UMLS Metathesaurus (requires license)",
        "Step 2: Extract MESH<->MONDO<->DOID cross-references",
        "Step 3: Integrate into disease_name_matcher.py",
        "Step 4: Re-evaluate with expanded disease coverage",
        "Step 5: Success criteria: >45% disease coverage, maintain R@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h10",
      "title": "Temporal Validation Split",
      "category": "evaluation",
      "rationale": "Current evaluation uses random disease split. Temporal split (train on pre-2020 approvals, test on 2020-2025) would better simulate real-world drug discovery and reduce optimistic bias.",
      "expected_impact": "low",
      "effort": "medium",
      "priority": 10,
      "status": "pending",
      "steps": [
        "Step 1: Download FDA approval dates from DrugBank or OpenFDA",
        "Step 2: Split GT: train on approvals pre-2020, test on 2020-2025",
        "Step 3: Retrain model on temporal training set",
        "Step 4: Evaluate R@30 on temporal test set",
        "Step 5: Report both temporal and random-split metrics",
        "Step 6: Success criteria: Establish temporal baseline, identify gap"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h11",
      "title": "Mechanism of Action Features",
      "category": "feature",
      "rationale": "Current model doesn't use drug mechanism directly. DrugBank has MoA annotations (agonist, antagonist, inhibitor). Matching MoA to disease pathophysiology could improve predictions.",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 11,
      "status": "pending",
      "steps": [
        "Step 1: Extract MoA from DrugBank (action field)",
        "Step 2: Create MoA categories: agonist, antagonist, inhibitor, modulator",
        "Step 3: Map diseases to expected MoA (e.g., diabetes -> agonist for insulin pathway)",
        "Step 4: Add MoA_match feature",
        "Step 5: Evaluate impact on R@30",
        "Step 6: Success criteria: >42.5% R@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h12",
      "title": "Node2Vec Embedding Refresh",
      "category": "architecture",
      "rationale": "Archive shows Node2Vec+XGBoost achieved 41.9% R@30 on held-out diseases (fair evaluation). Current TransE may be suboptimal. Retraining Node2Vec with DRKG + EC edges could improve.",
      "expected_impact": "medium",
      "effort": "high",
      "priority": 12,
      "status": "pending",
      "steps": [
        "Step 1: Augment DRKG with Every Cure treatment edges",
        "Step 2: Retrain Node2Vec embeddings (256-dim) on augmented graph",
        "Step 3: Extract new embeddings for all drugs/diseases",
        "Step 4: Retrain XGBoost on new embeddings",
        "Step 5: Evaluate on held-out diseases",
        "Step 6: Success criteria: >43% R@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h13",
      "title": "Confounding Pattern Expansion",
      "category": "data",
      "rationale": "Current confounding detector finds 9 patterns (1.6%). Expanding rules based on validation sessions (anti-IL-5, anti-IFN-gamma, TRAIL agonists) could filter more false positives.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 13,
      "status": "pending",
      "steps": [
        "Step 1: Review all false positive patterns from validation_sessions.md",
        "Step 2: Add rules for: anti-IL-5 for non-eosinophilic, IL-6 for psoriasis, anti-IFN-gamma for UC",
        "Step 3: Update confounding_detector.py with new patterns",
        "Step 4: Re-run confounding analysis",
        "Step 5: Success criteria: >5% confounding detection rate"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h14",
      "title": "Drug Formulation Filter",
      "category": "feature",
      "rationale": "Validation found intravitreal drugs (Brolucizumab) predicted for systemic diseases. Adding route-of-administration constraints could filter impractical predictions.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 14,
      "status": "pending",
      "steps": [
        "Step 1: Extract drug formulation from DrugBank (route field)",
        "Step 2: Flag intravitreal, topical-only, diagnostic-only drugs",
        "Step 3: Penalize predictions where route doesn't match disease type",
        "Step 4: Evaluate precision improvement",
        "Step 5: Success criteria: 10%+ precision improvement on biologics"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h15",
      "title": "Oncology Specialist Boosting",
      "category": "architecture",
      "rationale": "Oncology mAbs achieve 0-17% recall. Anti-HER2 and anti-EGFR particularly weak. Separate oncology model with tumor gene features could improve.",
      "expected_impact": "medium",
      "effort": "high",
      "priority": 15,
      "status": "pending",
      "steps": [
        "Step 1: Extract cancer disease subset from GT",
        "Step 2: Add tumor-specific features: driver mutations, tumor suppressor status",
        "Step 3: Train oncology-specific XGBoost model",
        "Step 4: Ensemble with general model for cancer predictions",
        "Step 5: Evaluate R@30 for cancer diseases",
        "Step 6: Success criteria: >25% R@30 for oncology (up from ~11%)"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h16",
      "title": "Clinical Trial Phase Features",
      "category": "feature",
      "rationale": "External validation uses ClinicalTrials.gov data. Adding trial phase as a feature (Phase 1/2/3) for known pairs could help model learn which combinations advance.",
      "expected_impact": "low",
      "effort": "medium",
      "priority": 16,
      "status": "pending",
      "steps": [
        "Step 1: Query ClinicalTrials.gov API for all drug-disease pairs",
        "Step 2: Extract max trial phase reached",
        "Step 3: Use as auxiliary training signal (semi-supervised)",
        "Step 4: Evaluate impact on novel prediction quality",
        "Step 5: Success criteria: >25% validation precision (up from 22.5%)"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h17",
      "title": "PPI Network Distance Features",
      "category": "feature",
      "rationale": "Drugs that target proteins close to disease genes in PPI network may be more effective. STRING database has PPI distances.",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 17,
      "status": "pending",
      "steps": [
        "Step 1: Download STRING PPI network for human",
        "Step 2: Compute shortest path from drug targets to disease genes",
        "Step 3: Add as feature: min_ppi_distance, mean_ppi_distance",
        "Step 4: Retrain GB with PPI features",
        "Step 5: Evaluate on held-out diseases",
        "Step 6: Success criteria: >42.5% R@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h18",
      "title": "Withdrawn Drug Filter Enhancement",
      "category": "data",
      "rationale": "Validation found predictions for withdrawn drugs (Pergolide, Aducanumab). Comprehensive withdrawn drug list could improve practical value of predictions.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 18,
      "status": "pending",
      "steps": [
        "Step 1: Download FDA withdrawn drug list from openFDA",
        "Step 2: Cross-reference with DrugBank withdrawal status",
        "Step 3: Add to confidence_filter.py exclusion list",
        "Step 4: Re-run filtering on all predictions",
        "Step 5: Success criteria: 100% exclusion of withdrawn drugs"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h19",
      "title": "Disease Phenotype Similarity",
      "category": "feature",
      "rationale": "Drugs that work for similar diseases may work for the target disease. HPO (Human Phenotype Ontology) similarity could capture this.",
      "expected_impact": "medium",
      "effort": "high",
      "priority": 19,
      "status": "pending",
      "steps": [
        "Step 1: Download HPO annotations for diseases",
        "Step 2: Compute disease-disease similarity using HPO semantic similarity",
        "Step 3: For each drug-disease pair, find max similarity to known indications",
        "Step 4: Add as feature (careful about leakage - use training diseases only)",
        "Step 5: Evaluate R@30 on held-out diseases",
        "Step 6: Success criteria: >42.5% R@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h20",
      "title": "Ensemble Score Calibration",
      "category": "ensemble",
      "rationale": "Current boosting formula (Quad Boost) was derived heuristically. Proper calibration via Platt scaling or isotonic regression could improve score interpretation.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 20,
      "status": "pending",
      "steps": [
        "Step 1: Hold out 20% of training pairs for calibration",
        "Step 2: Apply Platt scaling to raw GB scores",
        "Step 3: Evaluate calibration (Brier score, reliability diagram)",
        "Step 4: Compare calibrated vs uncalibrated R@30",
        "Step 5: Success criteria: Brier score < 0.15, maintain R@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h21",
      "title": "Multi-Indication Drug Bonus",
      "category": "feature",
      "rationale": "Drugs with many indications may have pleiotropic effects. Adding indication_count as feature could help identify repurposing candidates.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 21,
      "status": "pending",
      "steps": [
        "Step 1: Count known indications per drug from GT",
        "Step 2: Add indication_count as feature",
        "Step 3: Evaluate correlation with successful predictions",
        "Step 4: If positive, include in boosting formula",
        "Step 5: Success criteria: Positive correlation + >41.8% R@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h22",
      "title": "Rare Disease Focus Evaluation",
      "category": "evaluation",
      "rationale": "Every Cure prioritizes rare diseases. Separate evaluation on rare vs common diseases could identify where model performs best and where to focus improvements.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 22,
      "status": "pending",
      "steps": [
        "Step 1: Classify diseases as rare (prevalence < 1/2000) using Orphanet",
        "Step 2: Evaluate R@30 separately for rare vs common diseases",
        "Step 3: Identify performance gaps",
        "Step 4: Document findings for prioritization",
        "Step 5: Success criteria: Establish rare disease baseline metrics"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h23",
      "title": "TxGNN Full Ranking Storage (GPU Required)",
      "category": "data",
      "rationale": "To enable TxGNN ensembles, store full drug rankings (not just top-50) for all diseases. This requires GPU to generate but enables offline ensemble evaluation.",
      "expected_impact": "medium",
      "effort": "high",
      "priority": 23,
      "status": "pending",
      "steps": [
        "Step 1: Provision GPU on Vast.ai",
        "Step 2: Load TxGNN model (txgnn_500epochs.pt)",
        "Step 3: For each disease in ground truth, rank ALL 7954 drugs",
        "Step 4: Save as txgnn_full_rankings.csv (disease, drug, rank)",
        "Step 5: Re-test h1 and h2 with full rankings"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h24",
      "title": "GB Model Error Analysis by Drug Class",
      "category": "evaluation",
      "rationale": "GB model achieves 42% overall but varies by drug class. Understanding which drug classes perform best/worst can guide targeted improvements without TxGNN.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 24,
      "status": "pending",
      "steps": [
        "Step 1: Classify all drugs by ATC code (1st level)",
        "Step 2: Calculate R@30 per drug class",
        "Step 3: Identify best performers (e.g., ACE inhibitors 66.7%)",
        "Step 4: Identify worst performers (e.g., biologics 27.3%)",
        "Step 5: Document patterns for targeted feature engineering"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h25",
      "title": "Embedding Distance Calibration",
      "category": "feature",
      "rationale": "Current GB model uses raw embedding distances. Calibrating distances by drug/disease class could improve predictions for underperforming categories.",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 25,
      "status": "pending",
      "steps": [
        "Step 1: Compute embedding distances for all GT pairs",
        "Step 2: Compute distances for random negatives",
        "Step 3: Fit class-specific distance thresholds",
        "Step 4: Calibrate model predictions using class-specific priors",
        "Step 5: Evaluate R@30 improvement"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h26",
      "title": "Antibiotic Prediction Filtering Analysis",
      "category": "evaluation",
      "rationale": "The 13.6% figure was about antibiotics ranking poorly for infectious diseases. But evaluation shows model actually achieves 52% R@30 on infectious diseases. Need to understand: (1) which antibiotics are causing spurious predictions, (2) which non-infectious diseases they're predicted for, (3) whether existing confidence_filter.py adequately addresses this.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 26,
      "status": "pending",
      "steps": [
        "Step 1: Identify all antibiotic predictions in top-100 for non-infectious diseases",
        "Step 2: Categorize by antibiotic class and disease type",
        "Step 3: Analyze overlap with existing confidence_filter.py rules",
        "Step 4: Propose additional filtering rules if needed",
        "Step 5: Document patterns for future reference"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h27",
      "title": "Per-Category Baseline Documentation",
      "category": "evaluation",
      "rationale": "The discrepancy between reported 13.6% and actual 52% R@30 for infectious diseases suggests other category metrics may also be inaccurate. Need comprehensive baseline by disease category.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 27,
      "status": "pending",
      "steps": [
        "Step 1: Evaluate GB model on all disease categories (cancer, autoimmune, cardiovascular, etc.)",
        "Step 2: Record R@30 for each category with proper EC-to-DRKG mapping",
        "Step 3: Compare with figures in CLAUDE.md",
        "Step 4: Update CLAUDE.md with accurate category baselines",
        "Step 5: Identify categories that actually underperform for targeted improvement"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h28",
      "title": "DrugBank XML Indication Extraction",
      "category": "data",
      "rationale": "h4 showed 83% of identified missing FDA pairs hit@30, indicating value in GT expansion. Full DrugBank XML contains ~12K drug-indication pairs. Systematic extraction could add hundreds of missing pairs.",
      "expected_impact": "medium",
      "effort": "medium",
      "priority": 28,
      "status": "pending",
      "steps": [
        "Step 1: Download full DrugBank XML (requires academic license)",
        "Step 2: Parse indication data for all drugs",
        "Step 3: Map indications to MESH IDs using disease_name_matcher.py",
        "Step 4: Identify pairs not in current GT",
        "Step 5: Evaluate hit rate for new pairs",
        "Step 6: Add validated pairs to GT",
        "Success criteria: Identify >100 missing pairs with >70% hit@30"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h29",
      "title": "Verify Node2Vec Held-Out Disease Generalization",
      "category": "evaluation",
      "rationale": "h5 revealed GB+TransE can't generalize to unseen diseases (45.89% -> 3-12% R@30 with disease holdout). CLAUDE.md claims Node2Vec+XGBoost achieved 41.9% on held-out diseases, but code review shows train_with_node2vec.py uses PAIR-LEVEL split, not disease-level. Must verify: does Node2Vec genuinely generalize, or was this also inflated?",
      "expected_impact": "high",
      "effort": "low",
      "priority": 1,
      "status": "validated",
      "steps": [
        "Step 1: Load Node2Vec embeddings (256-dim from DRKG)",
        "Step 2: Apply SAME disease-level 80/20 split used in h5",
        "Step 3: Train XGBoost on training diseases only",
        "Step 4: Evaluate R@30 on held-out test diseases",
        "Step 5: Compare with TransE-based model under identical conditions",
        "Step 6: If Node2Vec generalizes, determine WHY (embedding properties, dimensionality, training method)",
        "Success criteria: Establish honest baseline for novel disease generalization"
      ],
      "findings": "VALIDATED: Node2Vec+XGBoost DOES generalize to unseen diseases, significantly outperforming TransE.\n\nRESULTS (88 held-out test diseases, seed=42):\n\n| Experiment | R@30 | Notes |\n|---|---|---|\n| Existing GB+TransE (pair-trained) | 45.89% | Trained on ALL diseases (inflated) |\n| Existing Node2Vec (pair-trained) | 21.64% | Trained on ALL diseases |\n| Node2Vec+XGBoost concat (disease holdout) | 26.18% | RETRAINED, unseen diseases |\n| Node2Vec+XGBoost cpd (disease holdout) | 29.45% | RETRAINED, unseen diseases, BEST |\n| TransE+XGBoost cpd (disease holdout) | 15.90% | RETRAINED, unseen diseases |\n| Node2Vec Cosine (no ML) | 1.27% | No model needed |\n| TransE Cosine (no ML) | 0.00% | No model needed |\n\nKEY FINDINGS:\n1. Node2Vec 29.45% vs TransE 15.90% on disease-level holdout \u2014 Node2Vec is 1.85x better\n2. The '41.9% on held-out diseases' claim was INCORRECT \u2014 it used pair-level split\n3. Concat+product+diff features HELP Node2Vec: 26.18% -> 29.45% (+3.3 pp)\n4. Cosine similarity alone is near-useless (0-1.27%) \u2014 ML model IS needed\n5. All 4 positive controls pass for Node2Vec concat model (Metformin rank 22, Rituximab rank 21, Imatinib rank 12, Lisinopril rank 27)\n6. Node2Vec's 29.45% generalization is a REAL signal \u2014 much better than TransE's 3-12% from h5\n\nIMPLICATIONS:\n1. Node2Vec embeddings capture transferable drug-disease patterns that TransE does not\n2. The embedding method is the critical factor for generalization\n3. 29.45% is the honest generalization baseline for novel disease prediction\n4. There is substantial room for improvement through hybrid features or better embeddings\n5. Node2Vec's random walk method captures neighborhood structure better than TransE's translational model",
      "result_metric": "29.45% R@30 on held-out diseases (Node2Vec+XGBoost cpd) vs 15.90% (TransE+XGBoost cpd)"
    },
    {
      "id": "h30",
      "title": "Graph Feature-Based Generalization",
      "category": "architecture",
      "rationale": "h5 showed embedding-only features (concat/product/diff) don't generalize to unseen diseases. Graph structural features (degree, path count, shared neighbors) may generalize better because they capture TOPOLOGICAL patterns that transfer across diseases. A drug that shares gene targets with known treatments for SIMILAR diseases should generalize.",
      "expected_impact": "high",
      "effort": "high",
      "priority": 2,
      "status": "pending",
      "steps": [
        "Step 1: Load DRKG graph (data/drkg/drkg.tsv)",
        "Step 2: For each drug-disease pair, compute: shortest path, number of paths <=3 hops, shared gene neighbors, drug degree, disease degree",
        "Step 3: Train XGBoost on graph features ONLY (no embeddings) with disease-level holdout",
        "Step 4: Train XGBoost on graph features + embeddings with disease-level holdout",
        "Step 5: Evaluate R@30 on held-out diseases",
        "Step 6: Compare generalization of graph-only vs embedding-only vs combined",
        "Success criteria: >20% R@30 on held-out diseases (vs 3-12% for embedding-only)"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h31",
      "title": "Inductive Disease Representation via Gene-Disease Features",
      "category": "architecture",
      "rationale": "The GB model fails on unseen diseases because disease EMBEDDINGS are opaque vectors that the model memorizes. If instead we represent diseases by their GENE associations (from disease_genes.json), the model could learn transferable patterns: 'drugs targeting protein X help diseases involving gene Y'. This is inductive \u2014 new diseases with known gene associations can be scored.",
      "expected_impact": "high",
      "effort": "medium",
      "priority": 3,
      "status": "pending",
      "steps": [
        "Step 1: Load disease_genes.json and drug_targets.json",
        "Step 2: Create disease feature vector: binary/count of associated genes (or top-N PCA components)",
        "Step 3: Create drug feature vector: binary/count of target genes",
        "Step 4: Features for pair: target-gene overlap, shared pathway count, drug target PCA, disease gene PCA",
        "Step 5: Train XGBoost with disease-level holdout",
        "Step 6: Evaluate R@30 on held-out diseases",
        "Success criteria: >25% R@30 on held-out diseases"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h32",
      "title": "Embedding Similarity Ranking (No ML Model)",
      "category": "evaluation",
      "rationale": "Perhaps the simplest approach is the right one: rank drugs by COSINE SIMILARITY to disease in embedding space, without training any ML model. This is inherently inductive (no disease-specific training needed). Previous attempts with TransE cosine caused data leakage, but with Node2Vec or properly evaluated TransE, simple similarity might be competitive.",
      "expected_impact": "medium",
      "effort": "low",
      "priority": 4,
      "status": "invalidated",
      "steps": [
        "Step 1: For each test disease, compute cosine similarity to ALL drugs using TransE embeddings",
        "Step 2: Rank drugs by similarity and compute R@30",
        "Step 3: Repeat with Node2Vec embeddings",
        "Step 4: Compare with GB model baseline",
        "Step 5: This requires NO training, so disease-level holdout is automatic",
        "Success criteria: Establish model-free baseline R@30"
      ],
      "findings": "INVALIDATED (tested as part of h29): Cosine similarity without ML is near-useless. Node2Vec cosine: 1.27% R@30, TransE cosine: 0.00% R@30. ML model IS required to learn drug-disease relationships from embeddings.",
      "result_metric": "Node2Vec cosine: 1.27% R@30, TransE cosine: 0.00% R@30"
    },
    {
      "id": "h33",
      "title": "Quantify Existing Model's True Generalization Gap",
      "category": "evaluation",
      "rationale": "h5 and h29 used a single disease split (seed=42). With h29 establishing 29.45% as baseline, multi-seed validation would strengthen confidence but is lower priority.",
      "expected_impact": "low",
      "effort": "low",
      "priority": 20,
      "status": "pending",
      "steps": [
        "Step 1: Run Node2Vec+XGBoost evaluation with 5 different random seeds for disease splits",
        "Step 2: Run TransE+XGBoost with same 5 seeds",
        "Step 3: Compute mean and std R@30 for both",
        "Step 4: Verify 28.73% vs 16.64% gap is consistent",
        "Success criteria: Quantify gap with confidence intervals"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h34",
      "title": "Node2Vec + Graph Topological Features Hybrid",
      "category": "architecture",
      "rationale": "h29 established Node2Vec+XGBoost at 29.45% R@30 on disease-level holdout. Graph topological features (shortest path, shared neighbors, path counts) are inherently inductive and could provide COMPLEMENTARY signal to Node2Vec embeddings.",
      "expected_impact": "high",
      "effort": "high",
      "priority": 1,
      "status": "pending",
      "steps": [
        "Step 1: Load DRKG graph from data/drkg/drkg.tsv",
        "Step 2: For each drug-disease pair, compute: shortest path length, number of paths <=3 hops, shared gene neighbors, drug degree, disease degree",
        "Step 3: Combine graph features WITH Node2Vec embedding features (concat)",
        "Step 4: Train XGBoost on graph+Node2Vec features with disease-level holdout (seed=42)",
        "Step 5: Also test graph features ONLY (without Node2Vec) for comparison",
        "Step 6: Evaluate R@30 on same 88 held-out test diseases from h29",
        "Success criteria: >33% R@30 (>3.5 pp improvement over Node2Vec-only 29.45%)"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h35",
      "title": "Node2Vec + Gene-Disease Feature Hybrid",
      "category": "architecture",
      "rationale": "h29 showed Node2Vec generalizes at 28.73%. Gene-based features (drug target genes, disease-associated genes, target-gene overlap) are fully inductive. Combining with Node2Vec could improve generalization.",
      "expected_impact": "high",
      "effort": "medium",
      "priority": 2,
      "status": "invalidated",
      "steps": [
        "Step 1: Load drug_targets.json and disease_genes.json from data/reference/",
        "Step 2: For each drug-disease pair, compute: # shared target-disease genes, Jaccard similarity of gene sets, PCA of drug target profile, PCA of disease gene profile",
        "Step 3: Combine gene features WITH Node2Vec embedding features",
        "Step 4: Train XGBoost with disease-level holdout (seed=42)",
        "Step 5: Also test gene features ONLY for comparison",
        "Step 6: Evaluate R@30 on held-out diseases",
        "Success criteria: >33% R@30"
      ],
      "findings": "INVALIDATED: Gene features provide minimal additional value on top of Node2Vec embeddings.\n\nRESULTS (88 held-out test diseases, seed=42):\n- Node2Vec only (baseline): 25.82% R@30 (142/550 hits)\n- Gene features only: 7.91% R@30 (44/556 hits)\n- Node2Vec + Gene hybrid: 26.55% R@30 (146/550 hits)\n- Delta: +0.73 pp (marginal, NOT meeting >33% target)\n\nGene features tested (12 features): n_shared, jaccard, dice, overlap_coeff, n_drug_targets, n_disease_genes, has_drug_targets, has_disease_genes, has_both, log_drug/disease/shared.\n\nFEATURE IMPORTANCE (hybrid model):\n- Node2Vec: 87.7%\n- Genes: 12.3% (dominated by n_drug_targets at 0.096)\n- Most gene interaction features (shared, jaccard, dice) have near-zero importance\n\nDATA COVERAGE: 63.5% of GT diseases have gene data, 36.9% of drugs have target data. 6,353 shared genes between drug targets and disease genes.\n\nWHY IT FAILED:\n1. Gene features are too sparse — most drug-disease pairs have zero shared genes\n2. Drug target count is the only useful gene feature, but it's drug-level not pair-level\n3. Node2Vec already captures gene-mediated relationships implicitly through the knowledge graph structure\n4. The 12 gene features add noise relative to 512 Node2Vec features\n\nIMPLICATION: Simple gene overlap features don't add to Node2Vec. More sophisticated gene representations (pathway-level, PPI network distance, gene expression similarity) might help, but require additional data.",
      "result_metric": "26.55% R@30 (hybrid) vs 25.82% (Node2Vec only) — +0.73 pp, below 33% target"
    },
    {
      "id": "h36",
      "title": "Node2Vec Hyperparameter Tuning for Generalization",
      "category": "architecture",
      "rationale": "Current Node2Vec uses default parameters (dim=256). The p and q parameters control walk behavior: p<1 favors BFS-like local exploration, q<1 favors DFS-like outward exploration. Different p/q settings might produce embeddings that generalize better to unseen diseases. Also, walk length and number of walks affect embedding quality.",
      "expected_impact": "medium",
      "effort": "high",
      "priority": 6,
      "status": "pending",
      "steps": [
        "Step 1: Identify current Node2Vec parameters (check if recorded in training logs)",
        "Step 2: Retrain Node2Vec with grid: p={0.5,1,2}, q={0.5,1,2} (9 combinations)",
        "Step 3: For each, train XGBoost and evaluate R@30 on disease-level holdout",
        "Step 4: Identify best p/q combination",
        "Step 5: Requires DRKG graph re-training \u2014 significant compute",
        "Success criteria: >33% R@30 with optimized parameters"
      ],
      "findings": null,
      "result_metric": null
    },
    {
      "id": "h37",
      "title": "Node2Vec Generalization Analysis by Disease Category",
      "category": "evaluation",
      "rationale": "h29 showed 28.73% overall R@30, but performance likely varies by disease category. Understanding which categories Node2Vec generalizes well/poorly for guides targeted improvement.",
      "expected_impact": "medium",
      "effort": "low",
      "priority": 3,
      "status": "validated",
      "steps": [
        "Step 1: Load h29 per-disease results from data/analysis/h29_node2vec_generalization_results.json",
        "Step 2: Categorize test diseases (cancer, autoimmune, cardiovascular, infectious, metabolic, neurological, etc.)",
        "Step 3: Compute per-category R@30 for Node2Vec vs TransE",
        "Step 4: Identify categories where Node2Vec excels vs fails",
        "Step 5: Compare with known category performance from CLAUDE.md (e.g., autoimmune 63%)",
        "Success criteria: Identify top 3 categories for improvement"
      ],
      "findings": "VALIDATED: Per-category analysis reveals extreme variation in Node2Vec generalization. TOP categories: ophthalmological 100% (2 diseases), hematological 70% (4), autoimmune 43.5% (6). MODERATE: cancer 19.3% (12), respiratory 31% (2). ZERO generalization: GI 0% (4), infectious 0% (5), rare/genetic 0% (2). Cardiovascular 10.2% (3) is a key gap. 49 diseases in 'other' category (19.1%) need better categorization. Best individuals: sarcoidosis 100%, autoimmune hemolytic anemia 100%, optic neuritis 100%. Worst: allergic rhinitis 0% (14 GT drugs), sepsis 0% (7 GT drugs). IMPLICATIONS: (1) Cardiovascular and infectious are highest-impact improvement targets, (2) Graph features (h34) may help sparse-connectivity diseases, (3) Gene features (h35) may help rare/genetic diseases.",
      "result_metric": "Overall 28.73% R@30; Best categories: ophthalmological 100%, hematological 70%, autoimmune 43.5%; Worst: GI/infectious/rare 0%"
    }
  ],
  "completed": [
    "h1",
    "h3",
    "h5",
    "h29",
    "h32",
    "h35",
    "h37"
  ],
  "learnings": [
    {
      "date": "2026-01-25",
      "finding": "Fuzzy disease matching improved R@30 from 37.4% to 41.8%",
      "source": "CLAUDE.md"
    },
    {
      "date": "2026-01-25",
      "finding": "Quad Boost features (target, ATC, chemical, pathway) are CIRCULAR and inflate metrics",
      "source": "CLAUDE.md"
    },
    {
      "date": "2026-01-25",
      "finding": "TxGNN achieves 83.3% R@30 on storage diseases but only 6.7% overall",
      "source": "txgnn_learnings.md"
    },
    {
      "date": "2026-01-25",
      "finding": "Biologic gap: mAbs have 2.1 diseases/drug vs 11.1 for small molecules",
      "source": "CLAUDE.md"
    },
    {
      "date": "2026-01-25",
      "finding": "Infectious disease paradox: more training data correlates with WORSE performance",
      "source": "CLAUDE.md"
    },
    {
      "date": "2026-01-25",
      "finding": "Validation precision: 22.5% for top predictions (batches 1+2)",
      "source": "validation_sessions.md"
    },
    {
      "date": "2026-01-26",
      "hypothesis_id": "h1",
      "finding": "TxGNN pre-computed predictions contain only top-50 drugs per disease. GT drugs are NOT in top-50 for most diseases (0% coverage). Ensemble blocked without GPU inference.",
      "implication": "h2 (Category-Routed Ensemble) has same blocker. TxGNN-based ensembles require live GPU inference, not pre-computed files."
    },
    {
      "date": "2026-01-26",
      "hypothesis_id": "h3",
      "finding": "The 13.6% infectious disease recall was antibiotic CLASS performance, not disease-level evaluation. Actual general model R@30 on infectious diseases is 52.0%.",
      "implication": "Specialist model unnecessary - general model already performs well. The real problem is spurious antibiotic predictions for non-infectious diseases, already handled by confidence_filter.py."
    },
    {
      "date": "2026-01-26",
      "hypothesis_id": "h4",
      "finding": "All 4,968 DRKG treatment edges are already in the 58K-pair GT. Only 6 additional FDA pairs found via manual search, 5/6 hit@30. Impact: +0.22 pp.",
      "implication": "GT expansion from public databases provides diminishing returns. Every Cure GT is comprehensive. Future expansion requires proprietary indication databases or careful manual curation."
    },
    {
      "date": "2026-01-27",
      "hypothesis_id": "h5",
      "finding": "CRITICAL FINDING: GB model with TransE embedding features (concat/product/diff) cannot generalize to held-out diseases. ALL 5 negative sampling strategies collapsed from 45.89% to 3-12% R@30 on disease-level holdout. The existing model's 41.8% R@30 is within-distribution performance, not novel disease generalization.",
      "implication": "This fundamentally changes the research direction: (1) Feature engineering and negative sampling improvements are IRRELEVANT if the model can't generalize; (2) The reported 41.8% R@30 is inflated \u2014 true generalization performance is much lower; (3) The Node2Vec approach (reportedly 41.9% on held-out diseases) may use a fundamentally different/better evaluation or embedding approach; (4) Future work must focus on architecture changes (better embeddings, graph features, or inductive models) rather than training data improvements."
    },
    {
      "date": "2026-01-27",
      "hypothesis_id": "h29",
      "finding": "Node2Vec+XGBoost achieves 28.73% R@30 on disease-level holdout (88 test diseases), vs 16.64% for TransE+XGBoost. The '41.9% on held-out diseases' claim was incorrect \u2014 original code used pair-level split. Node2Vec's random walk embeddings capture transferable patterns that TransE's translational model does not. Concat vs full features (concat+product+diff) make no difference for Node2Vec (both 28.73%). Cosine similarity alone is useless (0-1.27%).",
      "implication": "Node2Vec is the better embedding for generalization (1.73x TransE). The 28.73% establishes the honest generalization baseline. Future work should: (1) Use Node2Vec as the default embedding, (2) Investigate why Node2Vec generalizes better (neighborhood structure vs translational), (3) Improve beyond 28.73% through graph features, gene-based features, or better embeddings (e.g., augmented Node2Vec with more walk parameters), (4) Consider hybrid Node2Vec + graph feature approaches."
    },
    {
      "date": "2026-01-27",
      "hypothesis_id": "h35",
      "finding": "Gene-based features (shared genes, Jaccard, Dice, overlap coefficient, target counts) provide minimal additional value on top of Node2Vec: +0.73 pp (25.82% -> 26.55%). Gene-only model: 7.91% R@30. Feature importance: Node2Vec 87.7%, genes 12.3%. Most gene interaction features have near-zero importance; only n_drug_targets matters (0.096).",
      "implication": "Simple gene overlap features don't improve generalization because: (1) most drug-disease pairs have zero shared genes (sparsity), (2) Node2Vec already captures gene-mediated relationships implicitly through graph structure. More sophisticated representations needed: pathway-level features, PPI network distances, or gene expression similarity. Focus effort on graph topological features (h34) rather than gene-level features."
    },
    {
      "date": "2026-01-27",
      "hypothesis_id": "h37",
      "finding": "Node2Vec generalization varies dramatically by disease category: ophthalmological 100%, hematological 70%, autoimmune 43.5%, cancer 19.3%, cardiovascular 10.2%, infectious 0%, GI 0%, rare/genetic 0%. Dense KG connectivity correlates with generalization success.",
      "implication": "Improvement efforts should target: (1) cardiovascular diseases (10.2% with 59 GT drugs — high volume, moderate performance), (2) infectious diseases (0% with 14 GT drugs — complete failure), (3) GI diseases (0% with 9 GT drugs). Dense diseases (autoimmune, hematological) already work well. Graph topological features (h34) may help sparse-connectivity disease categories."
    }
  ]
}